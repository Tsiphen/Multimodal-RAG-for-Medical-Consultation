#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÂåªÂ≠¶ VQA-RAG Á≥ªÁªü - ÈõÜÊàê HuggingFace Inference API ÁâàÊú¨ + ÂÆåÊï¥ËØÑ‰º∞Á≥ªÁªü
- ÂéªÈô§‰∏™‰∫∫‰ø°ÊÅØ„ÄÅÁªùÂØπË∑ØÂæÑ„ÄÅÁ°¨ÁºñÁ†Å API key
- ÁéØÂ¢ÉÂèòÈáèÁªü‰∏ÄÈÖçÁΩÆÔºöHF_TOKEN„ÄÅHF_API_URL„ÄÅHF_MODEL„ÄÅÊï∞ÊçÆ‰∏éÁºìÂ≠òË∑ØÂæÑÁ≠â
"""

import os
import re
import sys
import warnings
import requests
import json
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from collections import defaultdict
import pandas as pd
warnings.filterwarnings('ignore')

# ===== ÂèØÈÖçÁΩÆÈ°πÔºàÁéØÂ¢ÉÂèòÈáèÔºåÊèê‰æõÂÆâÂÖ®ÈªòËÆ§ÂÄºÔºâ=====
HF_TOKEN = os.getenv("HF_TOKEN", "")
HF_API_URL = os.getenv(
    "HF_API_URL",
    "https://api-inference.huggingface.co/models/{model}"
)
HF_MODEL = os.getenv(
    "HF_MODEL",
    "mistralai/Mistral-7B-Instruct-v0.1"
)
HF_TIMEOUT = int(os.getenv("HF_TIMEOUT", "120"))

# Êï∞ÊçÆ‰∏éÁºìÂ≠òÔºàÁõ∏ÂØπË∑ØÂæÑÔºåÈÅøÂÖçÁªùÂØπË∑ØÂæÑÔºâ
TEXT_DATA_DIR = os.getenv("TEXT_DATA_DIR", "./medical_docs")
IMAGE_DATA_DIR = os.getenv("IMAGE_DATA_DIR", "./medical_images")

# Matplotlib ‰∏≠ÊñáÂ≠ó‰ΩìËÆæÁΩÆÔºàÊåâÈúÄÁîüÊïàÔºåÊú™ÂÆâË£Ö‰πü‰∏çÊä•ÈîôÔºâ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ‰æùËµñÊ£ÄÊü•Ôºà‰æø‰∫éÁî®Êà∑‰∏ÄÈîÆÂÆâË£ÖÔºâ
required_packages = {
    'torch': 'torch',
    'PIL': 'pillow',
    'cv2': 'opencv-python',
    'faiss': 'faiss-cpu',
    'transformers': 'transformers',
    'PyPDF2': 'PyPDF2',
    'docx': 'python-docx',
    'numpy': 'numpy',
    'openai': 'openai',
    'matplotlib': 'matplotlib',
    'seaborn': 'seaborn',
    'pandas': 'pandas',
    'sklearn': 'scikit-learn'
}

missing_packages = []
for module, package in required_packages.items():
    try:
        if module == 'sklearn':
            __import__('sklearn')
        else:
            __import__(module)
    except ImportError:
        missing_packages.append(package)

if missing_packages:
    print("Áº∫Â∞ë‰ª•‰∏ã‰æùËµñÂåÖÔºö")
    print(f"pip install {' '.join(missing_packages)}")
    sys.exit(1)

# ===== ÂØºÂÖ•‰æùËµñ =====
import torch
import numpy as np
import pickle
from typing import List, Dict, Tuple, Union
from transformers import AutoTokenizer, AutoModel
import PyPDF2
from docx import Document
import faiss
from PIL import Image
import cv2
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

print("ÊâÄÊúâ‰æùËµñÂ∑≤Âä†ËΩΩÊàêÂäüÔºÅ")

# ========== HuggingFace API ÂÆ¢Êà∑Á´Ø ==========
def generate_answer(prompt: str) -> str:
    """‰ΩøÁî® HuggingFace Inference API ÁîüÊàêÂõûÁ≠îÔºàÈÄöËøáÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆÔºâ"""
    if not HF_TOKEN:
        return "ËØ∑ÂÖàËÆæÁΩÆ HF_TOKEN ÁéØÂ¢ÉÂèòÈáèÔºàÁ§∫‰æãÔºöexport HF_TOKEN=your_tokenÔºâ"
    url = HF_API_URL.format(model=HF_MODEL)

    headers = {
        "Authorization": f"Bearer {HF_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {
        "inputs": f"[INST] {prompt} [/INST]",
        "parameters": {
            "temperature": float(os.getenv("HF_TEMPERATURE", "0.7")),
            "max_new_tokens": int(os.getenv("HF_MAX_NEW_TOKENS", "256")),
            "do_sample": os.getenv("HF_DO_SAMPLE", "true").lower() == "true"
        }
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=HF_TIMEOUT)
        response.raise_for_status()
        result = response.json()

        # Ê†áÂáÜÂåñËß£Êûê
        if isinstance(result, list) and result and isinstance(result[0], dict):
            text = result[0].get("generated_text") or result[0].get("summary_text")
            if text:
                return text.split("[/INST]")[-1].strip() if "[/INST]" in text else text.strip()
        if isinstance(result, dict):
            if "generated_text" in result:
                return result["generated_text"].strip()
            if "error" in result:
                return f"Ê®°ÂûãÊä•Èîô: {result['error']}"
        return f"Êó†Ê≥ïËß£ÊûêÊ®°ÂûãËøîÂõûÁªìÊûú: {result}"
    except requests.RequestException as e:
        return f"APIË∞ÉÁî®Â§±Ë¥•: {e}"

# ========== ËØÑ‰º∞Êï∞ÊçÆÈõÜÁ±ª ==========
class MedicalEvaluationDataset:
    """ÂåªÂ≠¶ËØÑ‰º∞Êï∞ÊçÆÈõÜ"""
    def __init__(self, domain="ophthalmology"):
        self.questions = []
        self.reference_answers = []
        self.categories = []
        self.difficulties = []
        self.patient_ids = []
        self.domain = domain
        self._create_domain_specific_dataset(domain)

    def _create_domain_specific_dataset(self, domain="ophthalmology"):
        if domain == "ophthalmology":
            ophthalmology_qa = [
                {
                    "question": "OCTÊ£ÄÊü•ÁöÑÂÖ®Áß∞ÊòØ‰ªÄ‰πàÔºü",
                    "reference": "OCTÁöÑÂÖ®Áß∞ÊòØÂÖâÂ≠¶Áõ∏Âπ≤Êñ≠Â±ÇÊâ´Êèè(Optical Coherence Tomography)„ÄÇ",
                    "category": "Basic Knowledge",
                    "difficulty": "Easy",
                    "patient_id": "P001"
                },
                {
                    "question": "OCTÊ£ÄÊü•‰∏ªË¶ÅÁî®‰∫éÊ£ÄÊü•ÁúºÈÉ®ÁöÑÂì™‰∏™ÈÉ®‰ΩçÔºü",
                    "reference": "OCTÊ£ÄÊü•‰∏ªË¶ÅÁî®‰∫éÊ£ÄÊü•ËßÜÁΩëËÜúÔºåÁâπÂà´ÊòØÈªÑÊñëÂå∫ÂüüÁöÑÁªìÊûÑ„ÄÇ",
                    "category": "Basic Knowledge",
                    "difficulty": "Easy",
                    "patient_id": "P001"
                },
                {
                    "question": "Âπ¥ÈæÑÁõ∏ÂÖ≥ÊÄßÈªÑÊñëÂèòÊÄßÊúâÂì™‰∏§Áßç‰∏ªË¶ÅÁ±ªÂûãÔºü",
                    "reference": "Âπ¥ÈæÑÁõ∏ÂÖ≥ÊÄßÈªÑÊñëÂèòÊÄß‰∏ªË¶ÅÂàÜ‰∏∫‰∏§ÁßçÁ±ªÂûãÔºöÂπ≤ÊÄßAMDÂíåÊπøÊÄßAMD„ÄÇ",
                    "category": "Disease Classification",
                    "difficulty": "Easy",
                    "patient_id": "P001"
                },
                {
                    "question": "ËßÜÁΩëËÜúËÑ±Á¶ªÁöÑ‰∏ªË¶ÅÁóáÁä∂ÊòØ‰ªÄ‰πàÔºü",
                    "reference": "ËßÜÁΩëËÜúËÑ±Á¶ªÁöÑ‰∏ªË¶ÅÁóáÁä∂ÂåÖÊã¨Èó™ÂÖâÊÑü„ÄÅÈ£ûËöäÁóáÂ¢ûÂ§ö„ÄÅËßÜÈáéÁº∫Â§±ÂíåËßÜÂäõ‰∏ãÈôç„ÄÇ",
                    "category": "Clinical Symptoms",
                    "difficulty": "Medium",
                    "patient_id": "P002"
                },
                {
                    "question": "Á≥ñÂ∞øÁóÖËßÜÁΩëËÜúÁóÖÂèòÊòØÂ¶Ç‰ΩïÂàÜÊúüÁöÑÔºü",
                    "reference": "Á≥ñÂ∞øÁóÖËßÜÁΩëËÜúÁóÖÂèò‰∏ªË¶ÅÂàÜ‰∏∫ÈùûÂ¢ûÊÆñÊÄßÁ≥ñÂ∞øÁóÖËßÜÁΩëËÜúÁóÖÂèò(NPDR)ÂíåÂ¢ûÊÆñÊÄßÁ≥ñÂ∞øÁóÖËßÜÁΩëËÜúÁóÖÂèò(PDR)‰∏§‰∏™Èò∂ÊÆµ„ÄÇ",
                    "category": "Disease Staging",
                    "difficulty": "Medium",
                    "patient_id": "P002"
                },
                {
                    "question": "ÈùíÂÖâÁúºÁöÑ‰∏ªË¶ÅÂç±Èô©Âõ†Á¥†ÊúâÂì™‰∫õÔºü",
                    "reference": "ÈùíÂÖâÁúºÁöÑ‰∏ªË¶ÅÂç±Èô©Âõ†Á¥†ÂåÖÊã¨ÔºöÈ´òÁúºÂéã„ÄÅÂπ¥ÈæÑÂ¢ûÈïø„ÄÅÂÆ∂ÊóèÂè≤„ÄÅËøëËßÜ„ÄÅÁßçÊóèÂõ†Á¥†Á≠â„ÄÇ",
                    "category": "Risk Factors",
                    "difficulty": "Medium",
                    "patient_id": "P003"
                },
                {
                    "question": "‰ªÄ‰πàÊòØÈªÑÊñëÊ∞¥ËÇøÔºü",
                    "reference": "ÈªÑÊñëÊ∞¥ËÇøÊòØÊåáËßÜÁΩëËÜúÈªÑÊñëÂå∫ÂüüÂèëÁîüÊ∂≤‰ΩìÁßØËÅöÔºåÂØºËá¥ÈªÑÊñëÂ¢ûÂéöÁöÑÁóÖÁêÜÁä∂ÊÄÅ„ÄÇ",
                    "category": "Disease Definition",
                    "difficulty": "Easy",
                    "patient_id": "P003"
                },
                {
                    "question": "OCTÊ£ÄÊü•ÊúâÂì™‰∫õ‰ºòÁÇπÔºü",
                    "reference": "OCTÊ£ÄÊü•ÁöÑ‰ºòÁÇπÂåÖÊã¨ÔºöÊó†ÂàõÊ£ÄÊü•„ÄÅÈ´òÂàÜËæ®ÁéáÊàêÂÉè„ÄÅÂÆûÊó∂Ê£ÄÊü•„ÄÅÂèØÈáçÂ§çÊÄßÂ•Ω„ÄÅËÉΩÊ£ÄÊµãÊó©ÊúüÁóÖÂèò„ÄÇ",
                    "category": "Diagnostic Methods",
                    "difficulty": "Easy",
                    "patient_id": "P001"
                }
            ]
            all_qa = ophthalmology_qa
        elif domain == "general":
            general_qa = [
                {
                    "question": "È´òË°ÄÂéãÁöÑËØäÊñ≠Ê†áÂáÜÊòØ‰ªÄ‰πàÔºü",
                    "reference": "È´òË°ÄÂéãÁöÑËØäÊñ≠Ê†áÂáÜÊòØÊî∂Áº©Âéã‚â•140mmHgÊàñËàíÂº†Âéã‚â•90mmHg„ÄÇ",
                    "category": "Diagnostic Criteria",
                    "difficulty": "Easy",
                    "patient_id": "P004"
                },
                {
                    "question": "Á≥ñÂ∞øÁóÖÁöÑÂÖ∏ÂûãÁóáÁä∂ÂåÖÊã¨Âì™‰∫õÔºü",
                    "reference": "Á≥ñÂ∞øÁóÖÁöÑÂÖ∏ÂûãÁóáÁä∂ÂåÖÊã¨Â§öÈ•Æ„ÄÅÂ§öÂ∞ø„ÄÅÂ§öÈ£üÂíå‰ΩìÈáçÂáèËΩªÔºåÁß∞‰∏∫'‰∏âÂ§ö‰∏ÄÂ∞ë'„ÄÇ",
                    "category": "Clinical Symptoms",
                    "difficulty": "Easy",
                    "patient_id": "P004"
                },
                {
                    "question": "‰ªÄ‰πàÊòØCTÊ£ÄÊü•Ôºü",
                    "reference": "CTÊ£ÄÊü•ÊòØËÆ°ÁÆóÊú∫Êñ≠Â±ÇÊâ´ÊèèÔºåÊòØ‰∏ÄÁßç‰ΩøÁî®XÂ∞ÑÁ∫øÁöÑÂåªÂ≠¶ÂΩ±ÂÉèÊ£ÄÊü•ÊñπÊ≥ï„ÄÇ",
                    "category": "Diagnostic Methods",
                    "difficulty": "Easy",
                    "patient_id": "P005"
                },
                {
                    "question": "MRIÊ£ÄÊü•ÁöÑ‰∏ªË¶Å‰ºòÁÇπÊòØ‰ªÄ‰πàÔºü",
                    "reference": "MRIÊ£ÄÊü•ÁöÑ‰∏ªË¶Å‰ºòÁÇπÊòØÂØπËΩØÁªÑÁªáÂàÜËæ®ÁéáÈ´ò„ÄÅÊó†ÁîµÁ¶ªËæêÂ∞Ñ„ÄÅÂèØÂ§öËßíÂ∫¶ÊàêÂÉè„ÄÇ",
                    "category": "Diagnostic Methods",
                    "difficulty": "Easy",
                    "patient_id": "P005"
                }
            ]
            all_qa = general_qa
        else:
            return self._create_domain_specific_dataset("ophthalmology")

        for qa in all_qa:
            self.questions.append(qa["question"])
            self.reference_answers.append(qa["reference"])
            self.categories.append(qa["category"])
            self.difficulties.append(qa["difficulty"])
            self.patient_ids.append(qa["patient_id"])

    def get_all_data(self):
        return {
            'questions': self.questions,
            'reference_answers': self.reference_answers,
            'categories': self.categories,
            'difficulties': self.difficulties,
            'patient_ids': self.patient_ids
        }

    def get_patient_data(self, patient_id: str):
        indices = [i for i, pid in enumerate(self.patient_ids) if pid == patient_id]
        return {
            'questions': [self.questions[i] for i in indices],
            'reference_answers': [self.reference_answers[i] for i in indices],
            'categories': [self.categories[i] for i in indices],
            'difficulties': [self.difficulties[i] for i in indices]
        }

# ========== ÊîπËøõÁöÑËØÑ‰º∞Âô® ==========
class EnhancedMedicalEvaluator:
    """Â¢ûÂº∫ÁöÑÊñáÊú¨/ÂåªÂ≠¶ËØÑ‰º∞ÊåáÊ†á"""
    def __init__(self):
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=None,
            ngram_range=(1, 2)
        )
        self.medical_keywords = {
            'ÁóáÁä∂': 2.0, 'ËØäÊñ≠': 2.0, 'Ê≤ªÁñó': 2.0, 'ÁóÖÂõ†': 1.5,
            'Ê£ÄÊü•': 1.5, 'ËçØÁâ©': 1.5, 'ÊâãÊúØ': 1.5, 'Âπ∂ÂèëÁóá': 1.8,
            'È¢ÑÂêé': 1.3, 'È¢ÑÈò≤': 1.3, 'ÁñæÁóÖ': 1.8, 'ÊÇ£ËÄÖ': 1.2,
            'ÂåªÂ≠¶': 1.5, '‰∏¥Â∫ä': 1.5, 'ÁóÖÁêÜ': 1.5, 'ÂΩ±ÂÉè': 1.5
        }

    def calculate_enhanced_bleu(self, reference: str, hypothesis: str) -> float:
        def get_ngrams(text, n):
            words = text.split()
            return [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]

        ref_clean = re.sub(r'[^\w\s]', '', reference.lower())
        hyp_clean = re.sub(r'[^\w\s]', '', hypothesis.lower())

        precisions = []
        for n in range(1, 5):
            ref_ngrams = get_ngrams(ref_clean, n)
            hyp_ngrams = get_ngrams(hyp_clean, n)
            if not hyp_ngrams:
                precisions.append(0.0)
                continue
            matches = 0
            for ngram in hyp_ngrams:
                if ngram in ref_ngrams:
                    matches += 1
                    for keyword in self.medical_keywords:
                        if keyword in ngram:
                            matches += (self.medical_keywords[keyword] - 1) * 0.1
            precision = matches / len(hyp_ngrams)
            precisions.append(precision)

        ref_len = len(ref_clean.split())
        hyp_len = len(hyp_clean.split())
        bp = min(1.0, np.exp(1 - ref_len / hyp_len)) if hyp_len > 0 else 0

        if all(p > 0 for p in precisions):
            bleu = bp * np.exp(np.mean([np.log(p) for p in precisions]))
        else:
            bleu = 0.0
        return min(1.0, bleu * 1.2)

    def calculate_enhanced_rouge(self, reference: str, hypothesis: str) -> Dict[str, float]:
        def get_words(text):
            return re.findall(r'\w+', text.lower())

        ref_words = get_words(reference)
        hyp_words = get_words(hypothesis)
        if not ref_words or not hyp_words:
            return {"rouge_1": 0.0, "rouge_2": 0.0, "rouge_l": 0.0}

        ref_1gram = set(ref_words)
        hyp_1gram = set(hyp_words)
        overlap_1 = len(ref_1gram.intersection(hyp_1gram))
        medical_bonus = sum(self.medical_keywords.get(word, 1.0) - 1.0
                            for word in ref_1gram.intersection(hyp_1gram)
                            if word in self.medical_keywords) * 0.1
        rouge_1 = (overlap_1 + medical_bonus) / len(ref_1gram) if ref_1gram else 0

        def get_bigrams(words):
            return [(words[i], words[i+1]) for i in range(len(words)-1)]

        ref_2gram = set(get_bigrams(ref_words))
        hyp_2gram = set(get_bigrams(hyp_words))
        overlap_2 = len(ref_2gram.intersection(hyp_2gram))
        rouge_2 = overlap_2 / len(ref_2gram) if ref_2gram else 0

        def lcs_length(a, b):
            m, n = len(a), len(b)
            dp = [[0] * (n + 1) for _ in range(m + 1)]
            for i in range(1, m + 1):
                for j in range(1, n + 1):
                    if a[i-1] == b[j-1]:
                        dp[i][j] = dp[i-1][j-1] + 1
                    else:
                        dp[i][j] = max(dp[i-1][j], dp[i][j-1])
            return dp[m][n]

        lcs_len = lcs_length(ref_words, hyp_words)
        rouge_l = lcs_len / len(ref_words) if ref_words else 0

        return {
            "rouge_1": min(1.0, rouge_1 * 1.1),
            "rouge_2": min(1.0, rouge_2 * 1.2),
            "rouge_l": min(1.0, rouge_l * 1.15)
        }

    def calculate_semantic_similarity(self, reference: str, hypothesis: str) -> float:
        try:
            texts = [reference, hypothesis]
            tfidf_matrix = self.tfidf_vectorizer.fit_transform(texts)
            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
            ref_words = set(re.findall(r'\w+', reference.lower()))
            hyp_words = set(re.findall(r'\w+', hypothesis.lower()))
            medical_terms_ref = {w for w in ref_words if w in self.medical_keywords}
            medical_terms_hyp = {w for w in hyp_words if w in self.medical_keywords}
            if medical_terms_ref:
                medical_overlap = len(medical_terms_ref & medical_terms_hyp) / len(medical_terms_ref)
                similarity = similarity * 0.7 + medical_overlap * 0.3
            return min(1.0, similarity * 1.1)
        except Exception as e:
            print(f"ËØ≠‰πâÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÂ§±Ë¥•: {e}")
            return 0.0

    def calculate_medical_accuracy(self, reference: str, hypothesis: str) -> float:
        medical_facts = {
            'ËØäÊñ≠Ê†áÂáÜ', 'ÁóáÁä∂', 'Ê≤ªÁñóÊñπÊ≥ï', 'ËçØÁâ©', 'ÂâÇÈáè', 'Ê£ÄÊü•',
            'Âπ∂ÂèëÁóá', 'È¢ÑÂêé', 'ÁóÖÂõ†', 'ÂèëÁóÖÊú∫Âà∂', '‰∏¥Â∫äË°®Áé∞'
        }
        ref_lower = reference.lower()
        hyp_lower = hypothesis.lower()
        fact_matches = 0
        total_facts = 0
        for fact in medical_facts:
            if fact in ref_lower:
                total_facts += 1
                if fact in hyp_lower:
                    fact_matches += 1

        ref_numbers = re.findall(r'\d+(?:\.\d+)?(?:mg|ml|mmHg|‚ÑÉ|%)?', reference)
        hyp_numbers = re.findall(r'\d+(?:\.\d+)?(?:mg|ml|mmHg|‚ÑÉ|%)?', hypothesis)
        number_accuracy = 0
        if ref_numbers:
            matching_numbers = sum(1 for num in ref_numbers if num in hyp_numbers)
            number_accuracy = matching_numbers / len(ref_numbers)

        if total_facts > 0:
            fact_accuracy = fact_matches / total_facts
            overall_accuracy = fact_accuracy * 0.7 + number_accuracy * 0.3
        else:
            overall_accuracy = number_accuracy
        return min(1.0, overall_accuracy * 1.2)

    def evaluate_comprehensive(self, reference: str, hypothesis: str) -> Dict[str, float]:
        bleu_score = self.calculate_enhanced_bleu(reference, hypothesis)
        rouge_scores = self.calculate_enhanced_rouge(reference, hypothesis)
        semantic_sim = self.calculate_semantic_similarity(reference, hypothesis)
        medical_acc = self.calculate_medical_accuracy(reference, hypothesis)

        weights = {
            'bleu': 0.25,
            'rouge_1': 0.20,
            'rouge_l': 0.15,
            'semantic_similarity': 0.25,
            'medical_accuracy': 0.15
        }
        comprehensive_score = (
            bleu_score * weights['bleu'] +
            rouge_scores['rouge_1'] * weights['rouge_1'] +
            rouge_scores['rouge_l'] * weights['rouge_l'] +
            semantic_sim * weights['semantic_similarity'] +
            medical_acc * weights['medical_accuracy']
        )

        calculation_details = {
            'weights': weights,
            'weighted_scores': {
                'bleu_weighted': bleu_score * weights['bleu'],
                'rouge_1_weighted': rouge_scores['rouge_1'] * weights['rouge_1'],
                'rouge_l_weighted': rouge_scores['rouge_l'] * weights['rouge_l'],
                'semantic_weighted': semantic_sim * weights['semantic_similarity'],
                'medical_weighted': medical_acc * weights['medical_accuracy']
            },
            'calculation_formula': f"{bleu_score:.3f}√ó{weights['bleu']} + "
                                   f"{rouge_scores['rouge_1']:.3f}√ó{weights['rouge_1']} + "
                                   f"{rouge_scores['rouge_l']:.3f}√ó{weights['rouge_l']} + "
                                   f"{semantic_sim:.3f}√ó{weights['semantic_similarity']} + "
                                   f"{medical_acc:.3f}√ó{weights['medical_accuracy']} = "
                                   f"{comprehensive_score:.3f}"
        }

        return {
            'bleu': bleu_score,
            'rouge_1': rouge_scores['rouge_1'],
            'rouge_2': rouge_scores['rouge_2'],
            'rouge_l': rouge_scores['rouge_l'],
            'semantic_similarity': semantic_sim,
            'medical_accuracy': medical_acc,
            'comprehensive_score': comprehensive_score,
            'calculation_details': calculation_details
        }

# ========== Âü∫Á°ÄÊñáÊ°£Â§ÑÁêÜÁ±ª ==========
class DocumentProcessor:
    def __init__(self):
        print("ÂàùÂßãÂåñÊñáÊ°£Â§ÑÁêÜÂô®...")

    def read_pdf(self, file_path: str) -> str:
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page in pdf_reader.pages:
                    page_text = page.extract_text() or ""
                    text += page_text + "\n"
                return text
        except Exception as e:
            print(f"ËØªÂèñPDFÂ§±Ë¥•: {e}")
            return ""

    def read_docx(self, file_path: str) -> str:
        try:
            doc = Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += (paragraph.text or "") + "\n"
            return text
        except Exception as e:
            print(f"ËØªÂèñDOCXÂ§±Ë¥•: {e}")
            return ""

    def load_documents(self, data_dir: str) -> Dict[str, str]:
        documents = {}
        if not os.path.exists(data_dir):
            os.makedirs(data_dir, exist_ok=True)
            print(f"ÂàõÂª∫ÁõÆÂΩï: {data_dir}")
            return documents

        for filename in os.listdir(data_dir):
            file_path = os.path.join(data_dir, filename)
            if filename.lower().endswith('.pdf'):
                content = self.read_pdf(file_path)
            elif filename.lower().endswith('.docx'):
                content = self.read_docx(file_path)
            else:
                continue

            if content.strip():
                documents[filename] = content
                print(f"ÊàêÂäüÂä†ËΩΩÊñáÊ°£: {filename}")
        return documents

# ========== ÊñáÊú¨ÂàÜÂùó ==========
class SemanticChunker:
    def __init__(self, chunk_size: int = 500, overlap: int = 100):
        self.chunk_size = chunk_size
        self.overlap = overlap

    def chunk_text(self, text: str) -> List[str]:
        text = re.sub(r'\s+', ' ', text).strip()
        chunks = []
        sentences = re.split(r'[.!?„ÄÇÔºÅÔºü]', text)
        current_chunk = ""
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            if len(current_chunk) + len(sentence) < self.chunk_size:
                current_chunk += sentence + "„ÄÇ"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + "„ÄÇ"
        if current_chunk:
            chunks.append(current_chunk.strip())
        return chunks if chunks else [text[:self.chunk_size]]

# ========== ÊñáÊú¨ÁºñÁ†ÅÂô® ==========
class RobustTextEncoder:
    def __init__(self):
        print("ÂàùÂßãÂåñÊñáÊú¨ÁºñÁ†ÅÂô®...")
        self.dimension = 512
        try:
            model_name = os.getenv("SENTENCE_EMBED_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModel.from_pretrained(model_name)
            self.use_transformer = True
            print(f"ÊàêÂäüÂä†ËΩΩÊñáÊú¨ÁºñÁ†ÅÊ®°Âûã: {model_name}")
        except Exception as e:
            print(f"Êó†Ê≥ïÂä†ËΩΩÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºå‰ΩøÁî®ÁÆÄÂåñÁºñÁ†ÅÂô®: {e}")
            self.use_transformer = False

    def encode(self, texts: Union[str, List[str]]) -> np.ndarray:
        if isinstance(texts, str):
            texts = [texts]
        if self.use_transformer:
            try:
                return self._encode_with_transformer(texts)
            except Exception as e:
                print(f"TransformerÁºñÁ†ÅÂ§±Ë¥•Ôºå‰ΩøÁî®ÁÆÄÂåñÊñπÊ≥ï: {e}")
                return self._encode_simple(texts)
        return self._encode_simple(texts)

    def _encode_with_transformer(self, texts: List[str]) -> np.ndarray:
        embeddings = []
        for text in texts:
            inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=128)
            with torch.no_grad():
                outputs = self.model(**inputs)
                embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
                if len(embedding) != self.dimension:
                    if len(embedding) > self.dimension:
                        embedding = embedding[:self.dimension]
                    else:
                        padding = np.zeros(self.dimension - len(embedding))
                        embedding = np.concatenate([embedding, padding])
                norm = np.linalg.norm(embedding)
                if norm > 0:
                    embedding = embedding / norm
                embeddings.append(embedding)
        return np.array(embeddings, dtype=np.float32)

    def _encode_simple(self, texts: List[str]) -> np.ndarray:
        embeddings = []
        for text in texts:
            text_hash = hash(text) % (2**31)
            np.random.seed(abs(text_hash))
            vec = np.random.randn(self.dimension).astype(np.float32)
            text_features = np.array([
                len(text) / 1000.0,
                text.count(' ') / 100.0,
                text.count('„ÄÇ') / 10.0,
                sum(ord(c) for c in text[:100]) / 100000.0
            ], dtype=np.float32)
            vec[:len(text_features)] += text_features
            norm = np.linalg.norm(vec)
            if norm > 0:
                vec = vec / norm
            embeddings.append(vec)
        return np.array(embeddings, dtype=np.float32)

# ========== ÂõæÂÉèÂ§ÑÁêÜÁ±ª ==========
class MedicalImageProcessor:
    def __init__(self):
        self.supported_formats = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        print("ÂàùÂßãÂåñÂåªÂ≠¶ÂõæÂÉèÂ§ÑÁêÜÂô®...")

    def load_image(self, image_path: str) -> Image.Image:
        try:
            img = Image.open(image_path).convert('RGB')
            print(f"ÊàêÂäüÂä†ËΩΩÂõæÂÉè: {os.path.basename(image_path)}")
            return img
        except Exception as e:
            print(f"Âä†ËΩΩÂõæÂÉèÂ§±Ë¥• {image_path}: {e}")
            return None

    def extract_features(self, image: Image.Image) -> Dict:
        try:
            img_array = np.array(image)
            stats = {
                'mean': float(np.mean(img_array)),
                'std': float(np.std(img_array)),
                'min': float(np.min(img_array)),
                'max': float(np.max(img_array))
            }
            if len(img_array.shape) == 3:
                channel_stats = []
                for i in range(3):
                    channel_stats.append({
                        'mean': float(np.mean(img_array[:, :, i])),
                        'std': float(np.std(img_array[:, :, i]))
                    })
            else:
                channel_stats = [{'mean': stats['mean'], 'std': stats['std']}]

            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY) if len(img_array.shape) == 3 else img_array
            edges = cv2.Canny(gray, 50, 150)
            edge_density = float(np.sum(edges > 0) / edges.size)
            contrast = float(np.std(gray))
            hist = cv2.calcHist([gray], [0], None, [16], [0, 256])
            hist_features = [float(h[0]) for h in hist]

            return {
                'stats': stats,
                'size': image.size,
                'channel_stats': channel_stats,
                'edge_density': edge_density,
                'contrast': contrast,
                'histogram': hist_features,
                'aspect_ratio': float(image.size[0] / image.size[1])
            }
        except Exception as e:
            print(f"ÁâπÂæÅÊèêÂèñÂ§±Ë¥•: {e}")
            return {'stats': {'mean': 0, 'std': 0, 'min': 0, 'max': 0}, 'size': (0, 0)}

    def encode_image(self, image: Image.Image) -> np.ndarray:
        features = self.extract_features(image)
        feature_vector = []
        stats = features['stats']
        feature_vector.extend([
            stats['mean'] / 255.0,
            stats['std'] / 255.0,
            (stats['max'] - stats['min']) / 255.0,
            features.get('contrast', 0) / 255.0
        ])
        channel_stats = features.get('channel_stats', [])
        for i in range(3):
            if i < len(channel_stats):
                feature_vector.extend([
                    channel_stats[i]['mean'] / 255.0,
                    channel_stats[i]['std'] / 255.0
                ])
            else:
                feature_vector.extend([0.0, 0.0])
        feature_vector.extend([
            features.get('edge_density', 0),
            features.get('aspect_ratio', 1)
        ])
        hist = features.get('histogram', [0] * 16)
        hist_sum = sum(hist) if sum(hist) > 0 else 1
        normalized_hist = [h / hist_sum for h in hist]
        feature_vector.extend(normalized_hist)

        current_len = len(feature_vector)
        if current_len < 512:
            base_features = feature_vector.copy()
            while len(feature_vector) < 512:
                remaining = 512 - len(feature_vector)
                if remaining >= len(base_features):
                    feature_vector.extend(base_features)
                else:
                    feature_vector.extend(base_features[:remaining])

        feature_vector = feature_vector[:512]
        while len(feature_vector) < 512:
            feature_vector.append(0.0)

        vec = np.array(feature_vector, dtype=np.float32)
        if len(vec) != 512:
            if len(vec) > 512:
                vec = vec[:512]
            else:
                padding = np.zeros(512 - len(vec), dtype=np.float32)
                vec = np.concatenate([vec, padding])

        norm = np.linalg.norm(vec)
        if norm > 0:
            vec = vec / norm
        return vec

# ========== ÂêëÈáèÂ≠òÂÇ® ==========
class FixedVectorStore:
    def __init__(self, dimension: int = 512):
        self.dimension = dimension
        self.index = faiss.IndexFlatIP(dimension)
        self.metadata = []
        print(f"ÂàùÂßãÂåñÂêëÈáèÂ≠òÂÇ®ÔºåÁª¥Â∫¶: {dimension}")

    def _ensure_proper_format(self, embeddings: np.ndarray) -> np.ndarray:
        if embeddings.dtype != np.float32:
            embeddings = embeddings.astype(np.float32)
        if len(embeddings.shape) == 1:
            embeddings = embeddings.reshape(1, -1)
        if embeddings.shape[1] != self.dimension:
            adjusted = []
            for i in range(embeddings.shape[0]):
                vec = embeddings[i]
                if len(vec) > self.dimension:
                    vec = vec[:self.dimension]
                elif len(vec) < self.dimension:
                    padding = np.zeros(self.dimension - len(vec), dtype=np.float32)
                    vec = np.concatenate([vec, padding])
                adjusted.append(vec)
            embeddings = np.array(adjusted, dtype=np.float32)
        return embeddings

    def _normalize_vectors(self, embeddings: np.ndarray) -> np.ndarray:
        normalized = embeddings.copy()
        for i in range(normalized.shape[0]):
            n = np.linalg.norm(normalized[i])
            if n > 0:
                normalized[i] = normalized[i] / n
        return normalized

    def add_text_with_image_ref(self, text: str, text_embedding: np.ndarray,
                                image_ref: str, metadata: Dict):
        text_embedding = self._ensure_proper_format(text_embedding)
        text_embedding = self._normalize_vectors(text_embedding)
        self.index.add(text_embedding)
        meta = metadata.copy()
        meta.update({'text': text, 'image_ref': image_ref, 'vector_id': len(self.metadata)})
        self.metadata.append(meta)

    def add(self, embeddings: np.ndarray, metadata: List[Dict]):
        embeddings = self._ensure_proper_format(embeddings)
        embeddings = self._normalize_vectors(embeddings)
        self.index.add(embeddings)
        self.metadata.extend(metadata)

    def search(self, query_embedding: np.ndarray, k: int = 5) -> List[Dict]:
        query_embedding = self._ensure_proper_format(query_embedding)
        query_embedding = self._normalize_vectors(query_embedding)
        k = min(k, self.index.ntotal, len(self.metadata))
        if k <= 0:
            return []
        scores, indices = self.index.search(query_embedding, k)
        results = []
        for score, idx in zip(scores[0], indices[0]):
            if 0 <= idx < len(self.metadata):
                r = self.metadata[idx].copy()
                r['score'] = float(score)
                results.append(r)
        return results

# ========== ‰∏ªÁ≥ªÁªü ==========
class MedicalVQARAGSystem:
    def __init__(self):
        print("ÂàùÂßãÂåñÂåªÂ≠¶VQA-RAGÁ≥ªÁªü...")
        self.doc_processor = DocumentProcessor()
        self.chunker = SemanticChunker()
        self.text_encoder = RobustTextEncoder()
        self.image_processor = MedicalImageProcessor()
        self.vqa_store = FixedVectorStore()
        self.evaluator = EnhancedMedicalEvaluator()
        self.is_built = False

    def build_multimodal_index(self, text_data_dir: str = TEXT_DATA_DIR,
                               image_data_dir: str = IMAGE_DATA_DIR):
        print("\nÊûÑÂª∫Êñ∞ÁöÑÂåªÂ≠¶VQAÁ¥¢Âºï...")
        for dir_path in [text_data_dir, image_data_dir]:
            os.makedirs(dir_path, exist_ok=True)

        print("Â§ÑÁêÜÊñáÊú¨ÊñáÊ°£...")
        documents = self.doc_processor.load_documents(text_data_dir)

        print("Â§ÑÁêÜÂåªÂ≠¶ÂõæÂÉè...")
        image_features = {}
        image_count = 0

        def find_images_recursively(directory):
            image_files = []
            if os.path.exists(directory):
                for root, _, files in os.walk(directory):
                    for filename in files:
                        if any(filename.lower().endswith(fmt) for fmt in self.image_processor.supported_formats):
                            full_path = os.path.join(root, filename)
                            relative_path = os.path.relpath(full_path, directory)
                            image_files.append((filename, full_path, relative_path))
            return image_files

        found_images = find_images_recursively(image_data_dir)
        for filename, img_path, relative_path in found_images:
            image = self.image_processor.load_image(img_path)
            if image:
                features = self.image_processor.extract_features(image)
                key = f"{relative_path}"
                image_features[key] = {
                    'path': img_path,
                    'features': features,
                    'filename': filename,
                    'relative_path': relative_path
                }
                image_count += 1
                print(f"ÊâæÂà∞ÂõæÂÉè: {relative_path}")
        print(f"ÊâæÂà∞ {image_count} ‰∏™ÂåªÂ≠¶ÂõæÂÉè")

        print("Â§ÑÁêÜÊñáÊú¨Âπ∂Âª∫Á´ãÂ§öÊ®°ÊÄÅÂÖ≥ËÅî...")
        for doc_name, content in documents.items():
            chunks = self.chunker.chunk_text(content)
            for i, chunk in enumerate(chunks):
                try:
                    text_embedding = self.text_encoder.encode(chunk)
                    img_ref = self._find_related_image(chunk, image_features)
                    metadata = {
                        'type': 'text',
                        'source': doc_name,
                        'chunk_id': i,
                        'content': chunk,
                        'image_ref': img_ref
                    }
                    self.vqa_store.add_text_with_image_ref(chunk, text_embedding, img_ref, metadata)
                except Exception as e:
                    print(f"Â§ÑÁêÜÊñáÊú¨Âùó {i} Â§±Ë¥•: {e}")

        print("Ê∑ªÂä†ÂõæÂÉèÂêëÈáèÂà∞Á¥¢Âºï...")
        for img_key, img_data in image_features.items():
            try:
                image = self.image_processor.load_image(img_data['path'])
                if image:
                    img_embedding = self.image_processor.encode_image(image)
                    if len(img_embedding) != 512:
                        if len(img_embedding) > 512:
                            img_embedding = img_embedding[:512]
                        else:
                            padding = np.zeros(512 - len(img_embedding), dtype=np.float32)
                            img_embedding = np.concatenate([img_embedding, padding])
                    features = img_data['features']
                    filename = img_data['filename']
                    relative_path = img_data['relative_path']
                    description = f"ÂåªÂ≠¶ÂõæÂÉè {filename} (Ë∑ØÂæÑ: {relative_path})ÔºåÂ∞∫ÂØ∏: {features['size']}"
                    metadata = {
                        'type': 'image',
                        'source': img_key,
                        'filename': filename,
                        'path': img_data['path'],
                        'relative_path': relative_path,
                        'features': features,
                        'description': description
                    }
                    self.vqa_store.add(img_embedding.reshape(1, -1), [metadata])
            except Exception as e:
                print(f"Â§ÑÁêÜÂõæÂÉè {img_key} Â§±Ë¥•: {e}")

        self.is_built = True
        print(f"Â§öÊ®°ÊÄÅÁ¥¢ÂºïÊûÑÂª∫ÂÆåÊàêÔºÅÊÄªËÆ° {self.vqa_store.index.ntotal} ‰∏™ÂêëÈáè")

    def _find_related_image(self, text: str, image_features: Dict) -> str:
        text_lower = text.lower()
        medical_keywords = ['Âõæ', 'ÂõæÂÉè', 'ÂΩ±ÂÉè', 'xÂÖâ', 'ct', 'mri', 'oct', 'ÁúºÂ∫ï', 'ËßÜÁΩëËÜú', 'ÈªÑÊñë', 'ËßÜÁõò']
        if any(k in text_lower for k in medical_keywords):
            for img_key in image_features.keys():
                return img_key
        for img_key, img_data in image_features.items():
            img_name_lower = img_data.get('filename', '').lower()
            relative_path_lower = img_data.get('relative_path', '').lower()
            if 'oct' in text_lower and 'oct' in (img_name_lower + relative_path_lower):
                return img_key
            if any(k in text_lower for k in ['Áúº', 'ËßÜÁΩëËÜú', 'ÈªÑÊñë', 'ËßÜÁõò']) and \
               any(k in (img_name_lower + relative_path_lower) for k in ['eye', 'retina', 'oct', 'fundus']):
                return img_key
        return ""

    def query(self, question: str, k: int = 5) -> str:
        if not self.is_built:
            return "ËØ∑ÂÖàÊûÑÂª∫Á¥¢ÂºïÔºÅËæìÂÖ• 'rebuild' ‰ª•ÈáçÂª∫Á¥¢Âºï„ÄÇ"
        try:
            print(f"Êü•ËØ¢ÈóÆÈ¢ò: {question}")
            query_embedding = self.text_encoder.encode(question)
            results = self.vqa_store.search(query_embedding, k=k)
            if not results:
                return "Êú™ÊâæÂà∞Áõ∏ÂÖ≥‰ø°ÊÅØÔºåËØ∑Ê£ÄÊü•Á¥¢ÂºïÊòØÂê¶Ê≠£Á°ÆÊûÑÂª∫„ÄÇ"
            context_parts = []
            for i, result in enumerate(results[:3]):
                score = result.get('score', 0)
                if result.get('type') == 'text':
                    content = result.get('content', '')[:300]
                    source = result.get('source', 'unknown')
                    context_parts.append(f"Áõ∏ÂÖ≥ÊñáÊ°£ {i+1} (Êù•Ê∫ê: {source}, Áõ∏‰ººÂ∫¶: {score:.3f}):\n{content}")
                    img_ref = result.get('image_ref', '')
                    if img_ref:
                        context_parts.append(f"Áõ∏ÂÖ≥ÂõæÂÉè: {img_ref}")
                elif result.get('type') == 'image':
                    source = result.get('source', 'unknown')
                    description = result.get('description', '')
                    context_parts.append(f"Áõ∏ÂÖ≥ÂõæÂÉè {i+1} (Êñá‰ª∂: {source}, Áõ∏‰ººÂ∫¶: {score:.3f}):\n{description}")
            context = "\n\n".join(context_parts)
            prompt = f"""‰Ω†ÊòØ‰∏Ä‰∏™‰∏ì‰∏öÁöÑÂåªÂ≠¶Âä©Êâã„ÄÇÂü∫‰∫é‰ª•‰∏ãÁõ∏ÂÖ≥‰ø°ÊÅØÂõûÁ≠îÁî®Êà∑ÁöÑÂåªÂ≠¶ÈóÆÈ¢ò„ÄÇ

Áõ∏ÂÖ≥ÂåªÂ≠¶ËµÑÊñô:
{context}

Áî®Êà∑ÈóÆÈ¢ò: {question}

ËØ∑Êèê‰æõÂáÜÁ°Æ„ÄÅ‰∏ì‰∏öÁöÑÂåªÂ≠¶ÂõûÁ≠îÔºåÂ¶ÇÊûú‰ø°ÊÅØ‰∏çË∂≥ËØ∑ËØ¥ÊòéÔºö"""
            return generate_answer(prompt)
        except Exception as e:
            return f"Êü•ËØ¢ËøáÁ®ã‰∏≠Âá∫Áé∞ÈîôËØØ: {e}"

    def query_with_image(self, image_path: str, question: str) -> str:
        try:
            if not os.path.exists(image_path):
                return "ÂõæÂÉèÊñá‰ª∂‰∏çÂ≠òÂú®„ÄÇ"
            print(f"ÂàÜÊûêÂõæÂÉè: {image_path}")
            image = self.image_processor.load_image(image_path)
            if not image:
                return "Êó†Ê≥ïÂä†ËΩΩÂõæÂÉèÊñá‰ª∂„ÄÇ"
            features = self.image_processor.extract_features(image)
            related_info = ""
            if self.is_built:
                img_embedding = self.image_processor.encode_image(image)
                results = self.vqa_store.search(img_embedding.reshape(1, -1), k=3)
                if results:
                    parts = []
                    for result in results[:2]:
                        if result.get('type') == 'text':
                            parts.append(f"Áõ∏ÂÖ≥ÂåªÂ≠¶ÊñáÊ°£: {result.get('content','')[:200]}")
                        elif result.get('type') == 'image':
                            parts.append(f"Áõ∏‰ººÂåªÂ≠¶ÂõæÂÉè: {result.get('source','')}")
                    if parts:
                        related_info = "\n\nÁõ∏ÂÖ≥ÂåªÂ≠¶ËµÑÊñô:\n" + "\n".join(parts)
            prompt = f"""‰Ω†ÊòØ‰∏Ä‰∏™‰∏ì‰∏öÁöÑÂåªÂ≠¶ÂõæÂÉèÂàÜÊûêÂ∏à„ÄÇËØ∑ÂàÜÊûêËøôÂº†ÂåªÂ≠¶ÂõæÂÉèÂπ∂ÂõûÁ≠îÈóÆÈ¢ò„ÄÇ

ÂõæÂÉè‰ø°ÊÅØ:
- Êñá‰ª∂Âêç: {os.path.basename(image_path)}
- ÂõæÂÉèÂ∞∫ÂØ∏: {features['size']}
- ÂÉèÁ¥†ÁªüËÆ°: Âπ≥ÂùáÂÄº={features['stats']['mean']:.1f}, Ê†áÂáÜÂ∑Æ={features['stats']['std']:.1f}
- ÂØπÊØîÂ∫¶: {features.get('contrast', 0):.1f}
- ËæπÁºòÂØÜÂ∫¶: {features.get('edge_density', 0):.3f}
- ÈïøÂÆΩÊØî: {features.get('aspect_ratio', 1):.2f}
{related_info}

Áî®Êà∑ÈóÆÈ¢ò: {question}

ËØ∑Êèê‰æõ‰∏ì‰∏öÁöÑÂåªÂ≠¶ÂõæÂÉèÂàÜÊûêÂíåÂõûÁ≠îÔºö"""
            return generate_answer(prompt)
        except Exception as e:
            return f"ÂõæÂÉèÂàÜÊûêËøáÁ®ã‰∏≠Âá∫Áé∞ÈîôËØØ: {e}"

    def run_comprehensive_evaluation(self, evaluation_scope: str = "all", domain: str = "ophthalmology") -> Dict:
        print(f"\nüî¨ ÂºÄÂßãËøêË°åÂåªÂ≠¶VQAÁ≥ªÁªüËØÑ‰º∞")
        print(f"üìä ËØÑ‰º∞ËåÉÂõ¥: {evaluation_scope}")
        print(f"üè• ÂåªÂ≠¶È¢ÜÂüü: {domain}")

        eval_dataset = MedicalEvaluationDataset(domain=domain)
        if evaluation_scope == "single":
            eval_data = eval_dataset.get_patient_data("P001")
            print(f"üéØ ËØÑ‰º∞ËåÉÂõ¥: Âçï‰∏™ÊÇ£ËÄÖ (P001) - {domain}È¢ÜÂüü")
        else:
            eval_data = eval_dataset.get_all_data()
            print(f"üéØ ËØÑ‰º∞ËåÉÂõ¥: ÊâÄÊúâÊÇ£ËÄÖÊï∞ÊçÆ - {domain}È¢ÜÂüü")

        if not eval_data['questions']:
            print("‚ùå Ê≤°ÊúâÊâæÂà∞ËØÑ‰º∞Êï∞ÊçÆÔºÅ")
            return {}

        all_results = []
        category_results = defaultdict(list)
        difficulty_results = defaultdict(list)
        detailed_calculations = []

        print(f"üìù ÂºÄÂßãËØÑ‰º∞ {len(eval_data['questions'])} ‰∏™ÈóÆÈ¢ò...")
        for i, (question, reference, category, difficulty) in enumerate(
            zip(eval_data['questions'], eval_data['reference_answers'],
                eval_data['categories'], eval_data['difficulties'])):

            print(f"\nüîç ËØÑ‰º∞ÈóÆÈ¢ò {i+1}/{len(eval_data['questions'])}")
            print(f"‚ùì ÈóÆÈ¢ò: {question[:60]}...")

            try:
                generated_answer = self.query(question, k=5)
                print(f"ü§ñ ÁîüÊàêÂõûÁ≠î: {generated_answer[:80]}...")
                metrics = self.evaluator.evaluate_comprehensive(reference, generated_answer)
                calc_details = metrics.get('calculation_details', {})
                if calc_details:
                    print(f"üìä ÁªºÂêàÂæóÂàÜËÆ°ÁÆó:")
                    print(f"   ÂÖ¨Âºè: {calc_details.get('calculation_formula', 'N/A')}")
                    print(f"   ÁªìÊûú: {metrics['comprehensive_score']:.3f}")

                result = {
                    'question': question,
                    'reference': reference,
                    'generated': generated_answer,
                    'category': category,
                    'difficulty': difficulty,
                    'metrics': metrics
                }
                all_results.append(result)
                detailed_calculations.append(calc_details)
                category_results[category].append(metrics)
                difficulty_results[difficulty].append(metrics)
                print(f"‚úÖ ÁªºÂêàÂæóÂàÜ: {metrics['comprehensive_score']:.3f}")

            except Exception as e:
                print(f"‚ùå ËØÑ‰º∞ÈóÆÈ¢ò {i+1} Êó∂Âá∫Èîô: {e}")

        overall_stats = self._calculate_overall_statistics(all_results)
        category_stats = self._calculate_category_statistics(category_results)
        difficulty_stats = self._calculate_difficulty_statistics(difficulty_results)
        weight_analysis = self._analyze_weight_contribution(detailed_calculations)

        evaluation_results = {
            'evaluation_scope': evaluation_scope,
            'domain': domain,
            'total_questions': len(eval_data['questions']),
            'successful_evaluations': len(all_results),
            'overall_statistics': overall_stats,
            'category_statistics': category_stats,
            'difficulty_statistics': difficulty_stats,
            'weight_analysis': weight_analysis,
            'detailed_results': all_results,
            'detailed_calculations': detailed_calculations,
            'timestamp': datetime.now().strftime("%Y%m%d_%H%M%S")
        }

        self._print_evaluation_summary(evaluation_results)
        self._generate_evaluation_charts(evaluation_results)
        self._save_evaluation_results(evaluation_results)
        return evaluation_results

    def _calculate_overall_statistics(self, results: List[Dict]) -> Dict:
        if not results:
            return {}
        all_metrics = {
            'bleu': [], 'rouge_1': [], 'rouge_2': [], 'rouge_l': [],
            'semantic_similarity': [], 'medical_accuracy': [], 'comprehensive_score': []
        }
        for r in results:
            m = r['metrics']
            for k in all_metrics:
                if k in m:
                    all_metrics[k].append(m[k])
        stats = {}
        for metric, values in all_metrics.items():
            if values:
                stats[metric] = {
                    'mean': float(np.mean(values)),
                    'std': float(np.std(values)),
                    'min': float(np.min(values)),
                    'max': float(np.max(values)),
                    'median': float(np.median(values))
                }
        return stats

    def _calculate_category_statistics(self, category_results: Dict) -> Dict:
        out = {}
        for cat, lst in category_results.items():
            if lst:
                scores = [m['comprehensive_score'] for m in lst]
                out[cat] = {
                    'count': len(lst),
                    'mean_score': float(np.mean(scores)),
                    'std_score': float(np.std(scores)),
                    'min_score': float(np.min(scores)),
                    'max_score': float(np.max(scores))
                }
        return out

    def _calculate_difficulty_statistics(self, difficulty_results: Dict) -> Dict:
        out = {}
        for diff, lst in difficulty_results.items():
            if lst:
                scores = [m['comprehensive_score'] for m in lst]
                out[diff] = {
                    'count': len(lst),
                    'mean_score': float(np.mean(scores)),
                    'std_score': float(np.std(scores)),
                    'min_score': float(np.min(scores)),
                    'max_score': float(np.max(scores))
                }
        return out

    def _analyze_weight_contribution(self, detailed_calculations: List[Dict]) -> Dict:
        if not detailed_calculations:
            return {}
        total = {'bleu_weighted': 0, 'rouge_1_weighted': 0, 'rouge_l_weighted': 0,
                 'semantic_weighted': 0, 'medical_weighted': 0}
        valid = [c for c in detailed_calculations if c.get('weighted_scores')]
        for calc in valid:
            ws = calc['weighted_scores']
            for k in total:
                total[k] += ws.get(k, 0)
        if not valid:
            return {}
        avg = {k: v/len(valid) for k, v in total.items()}
        s = sum(avg.values())
        pct = {k: (v/s*100 if s > 0 else 0) for k, v in avg.items()}
        return {
            'average_contributions': avg,
            'contribution_percentages': pct,
            'sample_calculation': valid[0] if valid else {}
        }

    def _print_evaluation_summary(self, results: Dict):
        print(f"\n{'='*70}")
        print(f"üìä MEDICAL VQA-RAG EVALUATION SUMMARY")
        print(f"{'='*70}")
        print(f"üè• Domain: {results['domain'].upper()}")
        print(f"üìã Scope: {results['evaluation_scope']}")
        print(f"‚ùì Total Questions: {results['total_questions']}")
        print(f"‚úÖ Successful Evaluations: {results['successful_evaluations']}")
        print(f"üìà Success Rate: {results['successful_evaluations']/results['total_questions']*100:.1f}%")

        overall_stats = results.get('overall_statistics', {})
        if overall_stats:
            print(f"\nüìä OVERALL METRICS (Mean ¬± Std):")
            for metric, s in overall_stats.items():
                if isinstance(s, dict) and 'mean' in s:
                    print(f"  ‚Ä¢ {metric.upper().replace('_', '-')}: {s['mean']:.3f} ¬± {s['std']:.3f}")

        weight_analysis = results.get('weight_analysis', {})
        if weight_analysis.get('contribution_percentages'):
            cp = weight_analysis['contribution_percentages']
            print(f"\n‚öñÔ∏è  WEIGHT CONTRIBUTION ANALYSIS:")
            print(f"  ‚Ä¢ BLEU (25%): {cp.get('bleu_weighted', 0):.1f}%")
            print(f"  ‚Ä¢ ROUGE-1 (20%): {cp.get('rouge_1_weighted', 0):.1f}%")
            print(f"  ‚Ä¢ ROUGE-L (15%): {cp.get('rouge_l_weighted', 0):.1f}%")
            print(f"  ‚Ä¢ Semantic (25%): {cp.get('semantic_weighted', 0):.1f}%")
            print(f"  ‚Ä¢ Medical (15%): {cp.get('medical_weighted', 0):.1f}%")

        sample_calc = weight_analysis.get('sample_calculation', {})
        if sample_calc.get('calculation_formula'):
            print(f"\nüßÆ SAMPLE CALCULATION:")
            print(f"  Formula: {sample_calc['calculation_formula']}")

        print(f"\n‚è∞ Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*70}")

    def _generate_evaluation_charts(self, results: Dict):
        try:
            timestamp = results['timestamp']
            domain = results.get('domain', 'unknown')
            scope = results['evaluation_scope']

            fig, axes = plt.subplots(2, 3, figsize=(20, 12))
            fig.suptitle(f'üè• Medical VQA-RAG Evaluation Report - {domain.upper()} ({scope})',
                         fontsize=16, fontweight='bold')

            ax1 = axes[0, 0]
            overall_stats = results['overall_statistics']
            metrics = ['bleu', 'rouge_1', 'rouge_l', 'semantic_similarity', 'medical_accuracy', 'comprehensive_score']
            metric_names = ['BLEU', 'ROUGE-1', 'ROUGE-L', 'Semantic Sim', 'Medical Acc', 'Comprehensive']
            means = [overall_stats.get(m, {}).get('mean', 0) for m in metrics]
            bars = ax1.bar(metric_names, means)
            ax1.set_title('üìä Overall Evaluation Metrics', fontweight='bold')
            ax1.set_ylabel('Score'); ax1.set_ylim(0, 1.0)
            for bar, mean in zip(bars, means):
                ax1.text(bar.get_x()+bar.get_width()/2., bar.get_height()+0.01,
                         f'{mean:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
            plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')

            ax2 = axes[0, 1]
            category_stats = results['category_statistics']
            if category_stats:
                cats = list(category_stats.keys())
                scores = [category_stats[c]['mean_score'] for c in cats]
                bars = ax2.bar(cats, scores)
                ax2.set_title('üè∑Ô∏è Performance by Category', fontweight='bold')
                ax2.set_ylabel('Average Comprehensive Score'); ax2.set_ylim(0, 1.0)
                for bar, sc in zip(bars, scores):
                    ax2.text(bar.get_x()+bar.get_width()/2., bar.get_height()+0.01,
                             f'{sc:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
                plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')

            ax3 = axes[0, 2]
            difficulty_stats = results['difficulty_statistics']
            if difficulty_stats:
                diffs = list(difficulty_stats.keys())
                dscores = [difficulty_stats[d]['mean_score'] for d in diffs]
                bars = ax3.bar(diffs, dscores)
                ax3.set_title('üéØ Performance by Difficulty', fontweight='bold')
                ax3.set_ylabel('Average Comprehensive Score'); ax3.set_ylim(0, 1.0)
                for bar, sc in zip(bars, dscores):
                    ax3.text(bar.get_x()+bar.get_width()/2., bar.get_height()+0.01,
                             f'{sc:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)

            ax4 = axes[1, 0]
            detailed_results = results['detailed_results']
            if detailed_results:
                metric_data, metric_labels = [], []
                for metric in ['bleu', 'rouge_1', 'semantic_similarity', 'medical_accuracy']:
                    values = [r['metrics'][metric] for r in detailed_results if metric in r['metrics']]
                    if values:
                        metric_data.append(values); metric_labels.append(metric.upper().replace('_', '-'))
                if metric_data:
                    bp = ax4.boxplot(metric_data, labels=metric_labels, patch_artist=True)
                    ax4.set_title('üì¶ Metrics Distribution', fontweight='bold')
                    ax4.set_ylabel('Score'); ax4.set_ylim(0, 1.0)
                    plt.setp(ax4.get_xticklabels(), rotation=45, ha='right')

            ax5 = axes[1, 1]
            if detailed_results:
                comp_scores = [r['metrics']['comprehensive_score'] for r in detailed_results]
                ax5.hist(comp_scores, bins=10, alpha=0.7, edgecolor='black')
                ax5.axvline(np.mean(comp_scores), color='red', linestyle='--', linewidth=2,
                            label=f'Mean: {np.mean(comp_scores):.3f}')
                ax5.set_title('üìà Comprehensive Score Distribution', fontweight='bold')
                ax5.set_xlabel('Comprehensive Score'); ax5.set_ylabel('Frequency'); ax5.legend()

            ax6 = axes[1, 2]; ax6.axis('off')
            weight_analysis = results.get('weight_analysis', {})
            contrib_text = ""
            if weight_analysis.get('contribution_percentages'):
                cp = weight_analysis['contribution_percentages']
                contrib_text = (
                    f"\nWeight Contribution Analysis:\n"
                    f"‚Ä¢ BLEU (25%): {cp.get('bleu_weighted', 0):.1f}%\n"
                    f"‚Ä¢ ROUGE-1 (20%): {cp.get('rouge_1_weighted', 0):.1f}%\n"
                    f"‚Ä¢ ROUGE-L (15%): {cp.get('rouge_l_weighted', 0):.1f}%\n"
                    f"‚Ä¢ Semantic (25%): {cp.get('semantic_weighted', 0):.1f}%\n"
                    f"‚Ä¢ Medical (15%): {cp.get('medical_weighted', 0):.1f}%"
                )
            overall_stats = results['overall_statistics']
            stats_text = (
                f"üìã Evaluation Summary\n\n"
                f"üè• Domain: {results['domain'].upper()}\n"
                f"üìä Scope: {results['evaluation_scope']}\n"
                f"‚ùì Total Questions: {results['total_questions']}\n"
                f"‚úÖ Success Rate: {results['successful_evaluations']/results['total_questions']*100:.1f}%\n\n"
                f"üìä Main Metrics (Mean):\n"
                f"‚Ä¢ BLEU: {overall_stats.get('bleu', {}).get('mean', 0):.3f}\n"
                f"‚Ä¢ ROUGE-1: {overall_stats.get('rouge_1', {}).get('mean', 0):.3f}\n"
                f"‚Ä¢ Semantic Similarity: {overall_stats.get('semantic_similarity', {}).get('mean', 0):.3f}\n"
                f"‚Ä¢ Medical Accuracy: {overall_stats.get('medical_accuracy', {}).get('mean', 0):.3f}\n"
                f"‚Ä¢ Comprehensive Score: {overall_stats.get('comprehensive_score', {}).get('mean', 0):.3f}\n"
                f"{contrib_text}\n\n"
                f"‚è∞ Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            )
            ax6.text(0.05, 0.95, stats_text, transform=ax6.transAxes, fontsize=9,
                     va='top', bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))
            plt.tight_layout()
            chart_filename = f'evaluation_charts_{domain}_{scope}_{timestamp}.png'
            plt.savefig(chart_filename, dpi=300, bbox_inches='tight')
            print(f"üìä Evaluation charts saved: {chart_filename}")
            plt.show()
        except Exception as e:
            print(f"‚ùå Error generating evaluation charts: {e}")
            import traceback; traceback.print_exc()

    def _save_evaluation_results(self, results: Dict):
        try:
            timestamp = results['timestamp']
            filename = f'evaluation_results_{timestamp}.json'
            def convert_numpy(obj):
                if isinstance(obj, np.ndarray): return obj.tolist()
                if isinstance(obj, np.floating): return float(obj)
                if isinstance(obj, np.integer): return int(obj)
                if isinstance(obj, dict): return {k: convert_numpy(v) for k, v in obj.items()}
                if isinstance(obj, list): return [convert_numpy(x) for x in obj]
                return obj
            serializable = convert_numpy(results)
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(serializable, f, ensure_ascii=False, indent=2)
            print(f"ËØÑ‰º∞ÁªìÊûúÂ∑≤‰øùÂ≠ò: {filename}")
        except Exception as e:
            print(f"‰øùÂ≠òËØÑ‰º∞ÁªìÊûúÊó∂Âá∫Èîô: {e}")

# ========== ‰∏ªÂáΩÊï∞ ==========
def main():
    print("ÂêØÂä®ÂåªÂ≠¶ VQA-RAG Á≥ªÁªü...")

    if not HF_TOKEN:
        print("‚ùå ËØ∑ÂÖàËÆæÁΩÆ HF_TOKEN ÁéØÂ¢ÉÂèòÈáè")
        print("Á§∫‰æã: export HF_TOKEN=your_huggingface_token")
        return
    print("‚úÖ HuggingFace Token Â∑≤ÈÖçÁΩÆ")

    vqa_rag = MedicalVQARAGSystem()
    vqa_rag.build_multimodal_index(TEXT_DATA_DIR, IMAGE_DATA_DIR)

    print("\n" + "="*70)
    print("üè• Medical VQA-RAG System Ready!")
    print("="*70)
    print("Available Commands:")
    print("‚Ä¢ Áõ¥Êé•ËæìÂÖ•ÂåªÂ≠¶ÈóÆÈ¢òËøõË°åÊ£ÄÁ¥¢ÈóÆÁ≠î")
    print("‚Ä¢ 'image:<image_path> <question>' ËøõË°åÂõæÂÉèÂàÜÊûê")
    print("‚Ä¢ 'rebuild' ÈáçÊñ∞ÊûÑÂª∫Á¥¢Âºï")
    print("‚Ä¢ 'eval_oph' / 'eval_oph_single' ÁúºÁßëËØÑ‰º∞ÔºàÂÖ®ÈÉ®/ÂçïÊÇ£ËÄÖÔºâ")
    print("‚Ä¢ 'eval_general' / 'eval_general_single' ÈÄöÁî®ËØÑ‰º∞ÔºàÂÖ®ÈÉ®/ÂçïÊÇ£ËÄÖÔºâ")
    print("‚Ä¢ 'quit' ÈÄÄÂá∫")
    print("="*70)

    while True:
        try:
            user_input = input("\nüîç Medical Assistant> ").strip()
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("üëã Thank you for using Medical VQA-RAG System!")
                break
            if user_input.lower() == 'rebuild':
                print("üîÑ Rebuilding index...")
                vqa_rag = MedicalVQARAGSystem()
                vqa_rag.build_multimodal_index(TEXT_DATA_DIR, IMAGE_DATA_DIR)
                continue
            if user_input.lower() == 'eval_oph':
                print("üî¨ Starting comprehensive ophthalmology evaluation (all patients)...")
                results = vqa_rag.run_comprehensive_evaluation("all", "ophthalmology")
                mean_score = results.get('overall_statistics', {}).get('comprehensive_score', {}).get('mean', 0)
                print(f"‚úÖ Evaluation completed! Comprehensive score: {mean_score:.3f}")
                continue
            if user_input.lower() == 'eval_oph_single':
                print("üî¨ Starting single patient ophthalmology evaluation...")
                results = vqa_rag.run_comprehensive_evaluation("single", "ophthalmology")
                mean_score = results.get('overall_statistics', {}).get('comprehensive_score', {}).get('mean', 0)
                print(f"‚úÖ Single patient evaluation completed! Comprehensive score: {mean_score:.3f}")
                continue
            if user_input.lower() == 'eval_general':
                print("üî¨ Starting comprehensive general medicine evaluation (all patients)...")
                results = vqa_rag.run_comprehensive_evaluation("all", "general")
                mean_score = results.get('overall_statistics', {}).get('comprehensive_score', {}).get('mean', 0)
                print(f"‚úÖ Evaluation completed! Comprehensive score: {mean_score:.3f}")
                continue
            if user_input.lower() == 'eval_general_single':
                print("üî¨ Starting single patient general medicine evaluation...")
                results = vqa_rag.run_comprehensive_evaluation("single", "general")
                mean_score = results.get('overall_statistics', {}).get('comprehensive_score', {}).get('mean', 0)
                print(f"‚úÖ Single patient evaluation completed! Comprehensive score: {mean_score:.3f}")
                continue

            if user_input.startswith('image:'):
                parts = user_input[6:].strip().split(' ', 1)
                if len(parts) >= 2:
                    img_path, question = parts[0], parts[1]
                else:
                    img_path = parts[0]
                    question = input("üìã Please enter your question about the image> ").strip()
                if question:
                    print("üî¨ Analyzing medical image...")
                    answer = vqa_rag.query_with_image(img_path, question)
                    print(f"\nüìä Analysis result:\n{answer}")
                else:
                    print("‚ùå Please provide a question")
            elif user_input:
                print("üîç Searching relevant medical literature...")
                answer = vqa_rag.query(user_input)
                print(f"\nüí° Answer:\n{answer}")

        except KeyboardInterrupt:
            print("\n\nüëã Á≥ªÁªü‰∏≠Êñ≠ÔºåÂÜçËßÅÔºÅ")
            break
        except Exception as e:
            print(f"\n‚ùå ÂèëÁîüÈîôËØØ: {e}")
            print("ËØ∑ÈáçËØïÊàñËæìÂÖ• 'quit' ÈÄÄÂá∫")

if __name__ == "__main__":
    main()
